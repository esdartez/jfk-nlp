{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1aee825f8d7f4ad29719798dfc166064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f081d7bc620426c8155a2544e68bf70",
              "IPY_MODEL_ea84c26c6a2e4324aaf51ce611b457c8",
              "IPY_MODEL_288e25937c9d45cb8e6711889d17f729"
            ],
            "layout": "IPY_MODEL_de43d7d47550434587fdb8b6ed518efd"
          }
        },
        "6f081d7bc620426c8155a2544e68bf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6241a2fb63274744991083892108b0b1",
            "placeholder": "​",
            "style": "IPY_MODEL_5c2a6bc4619244e19e03e2cf2cc86cfb",
            "value": "OCR Progress: 100%"
          }
        },
        "ea84c26c6a2e4324aaf51ce611b457c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c32b9f19a1042a48b5e0b0dc643b4c4",
            "max": 201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_503fbc3c29194836b6e03f31ffe81791",
            "value": 201
          }
        },
        "288e25937c9d45cb8e6711889d17f729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfed6fa3288341938426e9e08aae73f7",
            "placeholder": "​",
            "style": "IPY_MODEL_7a29e54a2d1247ba937b57b32685af8e",
            "value": " 201/201 [48:47&lt;00:00,  6.97s/it]"
          }
        },
        "de43d7d47550434587fdb8b6ed518efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6241a2fb63274744991083892108b0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2a6bc4619244e19e03e2cf2cc86cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c32b9f19a1042a48b5e0b0dc643b4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503fbc3c29194836b6e03f31ffe81791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfed6fa3288341938426e9e08aae73f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a29e54a2d1247ba937b57b32685af8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# JFK Document OCR Pipeline – Milestone 1\n",
        "**Author**: [Your Name]  \n",
        "**Objective**: Efficiently OCR a subset of JFK files with scalability to 100,000+ pages.  \n",
        "This notebook serves as a prototype pipeline for processing large historical document archives with preprocessing, parallel OCR, and basic NLP/EDA.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vNUmh3rLbSD1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4DIv9ngbEdl",
        "outputId": "f54de2a5-fb0f-4aa7-91cf-e9ce95bce753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.7 [186 kB]\n",
            "Fetched 186 kB in 0s (710 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126332 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.7_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y poppler-utils tesseract-ocr\n",
        "!pip install pytesseract pdf2image nltk tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Upload a Subset of JFK PDFs\n",
        "To simulate the full corpus, we'll work with a small subset (e.g., 10–20 pages). These PDFs are assumed to be scans requiring OCR.\n"
      ],
      "metadata": {
        "id": "1UQPbAfmbcLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Load ZIP archive\n",
        "zf = zipfile.ZipFile(zip_filename)\n",
        "\n",
        "# List of PDF files in the archive\n",
        "pdf_files = [f for f in zf.namelist() if f.lower().endswith(\".pdf\")]\n",
        "print(f\"Found {len(pdf_files)} PDF files in ZIP.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "cMWaACW_bWfA",
        "outputId": "f069bc5f-5132-496e-8523-6bcc3eb8ea03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c3b5b6b3-63a1-4d17-b5cd-a06a32c01381\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c3b5b6b3-63a1-4d17-b5cd-a06a32c01381\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving jfk2023f.zip to jfk2023f.zip\n",
            "Found 21 PDF files in ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Convert PDFs in ZIP to Images (In Memory)\n",
        "We'll convert only the first N PDFs for Milestone 1. Each will be OCR'd using the same parallelized method as before."
      ],
      "metadata": {
        "id": "G1v209MScPD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_bytes\n",
        "\n",
        "N = 3  # Number of PDFs to process for milestone\n",
        "images_all = []\n",
        "\n",
        "for pdf_name in pdf_files[:N]:\n",
        "    print(f\"Processing {pdf_name}\")\n",
        "    pdf_bytes = zf.read(pdf_name)\n",
        "    images = convert_from_bytes(pdf_bytes, dpi=200)\n",
        "    images_all.extend(images)  # Flatten all pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmSZjO-obZdx",
        "outputId": "df4e95e4-2060-43d1-faa2-baddec4047d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 104-10105-10271.pdf\n",
            "Processing 104-10120-10293.pdf\n",
            "Processing 104-10172-10108.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Image Preprocessing\n",
        "Preprocessing can improve OCR speed and quality. We'll convert images to grayscale and apply optional sharpening.\n"
      ],
      "metadata": {
        "id": "p_wFDGebcdN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageFilter\n",
        "\n",
        "def preprocess_image(img):\n",
        "    gray = img.convert(\"L\")  # Grayscale\n",
        "    sharpened = gray.filter(ImageFilter.SHARPEN)\n",
        "    return sharpened\n",
        "\n",
        "processed_images = [preprocess_image(img) for img in images]"
      ],
      "metadata": {
        "id": "R5dZ6vC8cep9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Parallelized OCR with Tesseract\n",
        "We use `ThreadPoolExecutor` to speed up OCR and `tqdm` to visualize progress.\n"
      ],
      "metadata": {
        "id": "oFhGshGlchOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def ocr_image(img):\n",
        "    return pytesseract.image_to_string(img, config='--psm 6')\n",
        "\n",
        "ocr_texts = []\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    ocr_texts = list(tqdm(executor.map(ocr_image, processed_images), total=len(processed_images), desc=\"OCR Progress\"))\n",
        "\n",
        "full_text = \"\\n\\n\".join([f\"--- Page {i+1} ---\\n{text}\" for i, text in enumerate(ocr_texts)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1aee825f8d7f4ad29719798dfc166064",
            "6f081d7bc620426c8155a2544e68bf70",
            "ea84c26c6a2e4324aaf51ce611b457c8",
            "288e25937c9d45cb8e6711889d17f729",
            "de43d7d47550434587fdb8b6ed518efd",
            "6241a2fb63274744991083892108b0b1",
            "5c2a6bc4619244e19e03e2cf2cc86cfb",
            "4c32b9f19a1042a48b5e0b0dc643b4c4",
            "503fbc3c29194836b6e03f31ffe81791",
            "cfed6fa3288341938426e9e08aae73f7",
            "7a29e54a2d1247ba937b57b32685af8e"
          ]
        },
        "id": "cC9XU9P2cg7S",
        "outputId": "fabc084b-7dfb-4fee-ff34-a26b84c2885f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "OCR Progress:   0%|          | 0/201 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aee825f8d7f4ad29719798dfc166064"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Save OCR Output\n",
        "We save the result as a `.txt` file for downstream NLP.\n"
      ],
      "metadata": {
        "id": "Ip9a5-uZck5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"jfk_ocr_output.txt\", \"w\") as f:\n",
        "    f.write(full_text)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"jfk_ocr_output.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "APICts9Kcmvw",
        "outputId": "58734a45-59cb-4186-a47b-b4c26d161659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c0ed95c7-31c8-4af2-a4aa-6ad267c3b421\", \"jfk_ocr_output.txt\", 504259)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 6: Light NLP & EDA\n",
        "We’ll analyze word frequencies to preview the contents. This also sets the stage for future topic modeling and sentiment analysis.\n"
      ],
      "metadata": {
        "id": "AlUYHqnmcyWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Tokenize and clean\n",
        "words = re.findall(r'\\b[a-zA-Z]{3,}\\b', full_text.lower())\n",
        "filtered_words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "\n",
        "# Count\n",
        "word_counts = Counter(filtered_words)\n",
        "top_words = word_counts.most_common(20)\n",
        "\n",
        "# Display\n",
        "for word, freq in top_words:\n",
        "    print(f\"{word}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RfdJ30Ucz9-",
        "outputId": "f21373a3-e5f4-4240-a8a4-9daf155b5bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "david: 229\n",
            "page: 222\n",
            "halperin: 213\n",
            "says: 204\n",
            "know: 186\n",
            "see: 184\n",
            "well: 184\n",
            "eee: 176\n",
            "going: 141\n",
            "get: 124\n",
            "asks: 119\n",
            "would: 116\n",
            "right: 112\n",
            "talk: 108\n",
            "yes: 104\n",
            "one: 100\n",
            "call: 90\n",
            "tho: 83\n",
            "end: 82\n",
            "take: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assume one OCR chunk per page\n",
        "doc_lengths = [len(doc.split()) for doc in ocr_texts]  # ocr_texts is list of page texts\n",
        "\n",
        "print(f\"Total docs: {len(doc_lengths)}\")\n",
        "print(f\"Avg doc length: {np.mean(doc_lengths):.2f} words\")\n",
        "print(f\"Min: {np.min(doc_lengths)}, Max: {np.max(doc_lengths)}, Std: {np.std(doc_lengths):.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxS3vB5FrO6x",
        "outputId": "c802ad84-65ac-491e-ced4-0e4e4f3f2c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total docs: 201\n",
            "Avg doc length: 563.35 words\n",
            "Min: 65, Max: 1373, Std: 267.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = set(filtered_words)\n",
        "hapax_words = [w for w in unique_words if word_counts[w] == 1]\n",
        "hapax_ratio = len(hapax_words) / len(unique_words)\n",
        "print(f\"Hapax Legomena Ratio: {hapax_ratio:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqlKKxn1rUxd",
        "outputId": "7c3a3fc1-6fe8-4f2d-db1a-e15c83140138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hapax Legomena Ratio: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams\n",
        "from collections import defaultdict\n",
        "\n",
        "bi_counts = defaultdict(int)\n",
        "for b in bigrams(filtered_words):\n",
        "    bi_counts[b] += 1\n",
        "\n",
        "top_bigrams = sorted(bi_counts.items(), key=lambda x: x[1], reverse=True)[:15]\n",
        "for (w1, w2), freq in top_bigrams:\n",
        "    print(f\"{w1} {w2}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm3eLRdurWpT",
        "outputId": "e489d550-bc68-435b-939a-47556a72f114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "would like: 27\n",
            "maurice halperin: 27\n",
            "mexico city: 24\n",
            "wants know: 20\n",
            "reproduction issuing: 14\n",
            "issuing office: 12\n",
            "office prohibited: 12\n",
            "page real: 12\n",
            "prohibited copy: 11\n",
            "end message: 11\n",
            "classified message: 10\n",
            "page page: 10\n",
            "next week: 10\n",
            "secret page: 9\n",
            "halperin lupe: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(full_text[:20000])  # Limit to first 20k chars for speed\n",
        "\n",
        "entities = list(doc.ents)  # Keep actual spaCy Span objects\n",
        "entity_counter = Counter(ent.label_ for ent in entities)\n",
        "print(\"Named entity types:\", entity_counter)\n",
        "\n",
        "# Most common named entities\n",
        "from collections import Counter\n",
        "\n",
        "name_counter = Counter([ent.text for ent in entities if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]])\n",
        "print(\"Top 10 named entities:\")\n",
        "for name, count in name_counter.most_common(10):\n",
        "    print(f\"{name}: {count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYtr_W1prd5u",
        "outputId": "e53f43a3-bab5-4b0a-86de-9ce218dced5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Named entity types: Counter({'CARDINAL': 180, 'ORG': 170, 'PERSON': 162, 'GPE': 51, 'DATE': 40, 'PRODUCT': 17, 'NORP': 16, 'MONEY': 13, 'WORK_OF_ART': 6, 'QUANTITY': 5, 'FAC': 3, 'LOC': 3, 'PERCENT': 3, 'EVENT': 2, 'TIME': 2, 'LAW': 1})\n",
            "Top 10 named entities:\n",
            "Lo: 10\n",
            "Subj: 4\n",
            "Se: 3\n",
            "Subject: 3\n",
            "ER: 2\n",
            "Sn: 2\n",
            "Lugano: 2\n",
            "Prague: 2\n",
            "Csech: 2\n",
            "STR: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "output_path = \"output/nlp_summary_report.csv\"\n",
        "\n",
        "with open(output_path, \"w\", newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # Section 1: Document Statistics\n",
        "    doc_lengths = [len(doc.split()) for doc in ocr_texts]\n",
        "    writer.writerow([\"Document Length Statistics\"])\n",
        "    writer.writerow([\"Metric\", \"Value\"])\n",
        "    writer.writerow([\"Total Pages\", len(doc_lengths)])\n",
        "    writer.writerow([\"Average Length (words)\", round(np.mean(doc_lengths), 2)])\n",
        "    writer.writerow([\"Min Length\", np.min(doc_lengths)])\n",
        "    writer.writerow([\"Max Length\", np.max(doc_lengths)])\n",
        "    writer.writerow([\"Std Dev\", round(np.std(doc_lengths), 2)])\n",
        "    writer.writerow([])\n",
        "\n",
        "    # Section 2: Top Words\n",
        "    writer.writerow([\"Top 20 Most Frequent Words\"])\n",
        "    writer.writerow([\"Word\", \"Frequency\"])\n",
        "    for word, freq in top_words[:20]:\n",
        "        writer.writerow([word, freq])\n",
        "    writer.writerow([])\n",
        "\n",
        "    # Section 3: Top Bigrams\n",
        "    writer.writerow([\"Top 20 Bigrams\"])\n",
        "    writer.writerow([\"Bigram\", \"Frequency\"])\n",
        "    for (w1, w2), freq in top_bigrams[:20]:\n",
        "        writer.writerow([f\"{w1} {w2}\", freq])\n",
        "    writer.writerow([])\n",
        "\n",
        "    # Section 4: Named Entity Types\n",
        "    writer.writerow([\"Named Entity Types\"])\n",
        "    writer.writerow([\"Entity Type\", \"Count\"])\n",
        "    for label, count in entity_counter.most_common(20):\n",
        "        writer.writerow([label, count])\n",
        "    writer.writerow([])\n",
        "\n",
        "    # Section 5: Top Named Entities\n",
        "    writer.writerow([\"Top 20 Named Entities (PERSON, ORG, GPE)\"])\n",
        "    writer.writerow([\"Entity\", \"Mentions\"])\n",
        "    for name, count in name_counter.most_common(20):\n",
        "        writer.writerow([name, count])\n",
        "    writer.writerow([])\n",
        "\n",
        "    # Section 6: Lexical Richness\n",
        "    hapax_words = [w for w in set(filtered_words) if word_counts[w] == 1]\n",
        "    hapax_ratio = len(hapax_words) / len(set(filtered_words))\n",
        "    writer.writerow([\"Lexical Richness\"])\n",
        "    writer.writerow([\"Metric\", \"Value\"])\n",
        "    writer.writerow([\"Hapax Legomena Ratio\", round(hapax_ratio, 4)])\n",
        "\n",
        "print(f\" NLP summary written to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftYzSNBAsREq",
        "outputId": "4e39aafa-a3f0-4c82-fc10-d8c4c2081625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NLP summary written to output/nlp_summary_report.csv\n"
          ]
        }
      ]
    }
  ]
}